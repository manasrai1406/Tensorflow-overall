# -*- coding: utf-8 -*-
"""practice-with-Tensors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LF7XdI-HFxLs70dYA_DC-LHCihMkSud-
"""

import tensorflow as tf
print(tf.__version__)

scalar=tf.constant(7)
scalar

#dimensions of the scalar
scalar.ndim

#creating a vector
vector = tf.constant([10,10])
vector

vector.ndim

#create a matrix
matrix = tf.constant([[10,7],[10,7]])
matrix

matrix.ndim

#create another matrix
another_matrix = tf.constant([[10.,7.],[3.,2.],[10. ,9.]],dtype = tf.float16)
another_matrix

another_matrix.ndim

#creating a tensor(n dimensions)
tensor = tf.constant([[[1 ,2 ,3],
                      [4 ,5 ,6]],
                      [[7 ,8 ,9],
                       [10 ,11 , 12]],
                      [[13 ,14 ,25],
                       [16 ,17 ,18]]])
tensor

tensor.ndim

"""#Scalar: A Single number
#vector: A number with direction
#matrix: 2-D array of numbers
#Tensor:A n-Dimensional vector
"""

###creating tensor with tf.variable

changeable_tensor = tf.Variable([10,7])
unchangeable_tensor = tf.constant([10,7])
changeable_tensor,unchangeable_tensor

#changing the value of a tensor
changeable_tensor[0].assign(7)
changeable_tensor

#Creating random Tensors

random_1 = tf.random.Generator.from_seed(42) #set seed for reproducibiity
random_1 = random_1.normal(shape = (3,2))
random_2 = tf.random.Generator.from_seed(42)
random_2 = random_2.normal(shape = (3,2))
random_1,random_2 , random_1 == random_2

#shuffling the order of elements in a Tensor(valuable when we need to shuffle the order to prevent inherent order)

not_shuffled = tf.constant([[10,7],
                 [3,4],
                 [2,5]])
not_shuffled.ndim

tf.random.shuffle(not_shuffled)
#shuffled seed

"""# Creating Tensors from NumPy Arrays"""

tf.ones([10,7])

tf.zeros(shape = (3,4))

#converting Numpy arrays into Tensors
#tensors can be run on a gpu for much faster numerical computing as compared to NumPy arrays
import numpy as np
numpy_A = np.arange(1,25 , dtype = np.int32)
numpy_A 

#X = tf.constant(some_matrix)     #Capital for matrix ot Tensor
#y=tf.constant(vector)            #Non-Capital for vector

A=tf.constant(numpy_A,shape = (3,8))
A

"""# Getting information out of **Tensors**

## Following info can be taken out from Tensors
*shape
*Rank
*Axis
*Dimension
"""

rank_4_tensor = tf.zeros(shape=[2,3,4,5]) 
rank_4_tensor

rank_4_tensor[0]

rank_4_tensor.shape,rank_4_tensor.ndim,tf.size(rank_4_tensor)

"""Tensors can be indexed just like python Lists"""

rank_4_tensor[:2,:2,:2,:2]

rank_4_tensor[:1,:1,:1, :]

rank_2_tensor = tf.constant([[10,7],
                            [3,4]])
rank_2_tensor

rank_3_tensor=rank_2_tensor[...,tf.newaxis]
rank_3_tensor

#Alternative to newaxis
tf.expand_dims(rank_2_tensor,axis =-1)  #-1 means expand the final axis

tf.expand_dims(rank_2_tensor,axis=0)   #output will be      shape = (1,2,2)
tf.expand_dims(rank_2_tensor,axis=1)     #output will be    shape = (2,1,2)
#axis is used to name column for adding the dimension

"""# Manipulating Tensors (Tensor operations)

## Basic Operations('+','-','*','/')
"""

tensor = tf.constant([[10,7],[3,4]])
tensor+10                                     #original tensor remains unchanged

tensor*10
#using tensorflow library same output for these can be get
tf.multiply(tensor,10)

"""Matrix Multiplication"""

tf.matmul(tensor,tensor)

#Alternative to tf.matmul is tf.tensordot

"""Aggregating Tensors"""

#Condensing tensors from multiple values to smaller amount of values
d = tf.constant([-10,-7])
d

tf.abs(d)

E = tf.constant(np.random.randint(0,100,size = 50))
E

tf.reduce_min(E)

tf.reduce_max(E)

#Finding the mean
tf.reduce_mean(E)

tf.reduce_sum(E)

###squeezing a tensor(removing all single dimensions)
tf.random.set_seed(42)
G = tf.constant(tf.random.uniform(shape=[50]),shape=(1,1,1,1,50))

G_squeezed = tf.squeeze(G)
G_squeezed,G_squeezed.shape

"""###one-hot encoding Tensors

"""

some_list =[0,1,2,3]
tf.one_hot(some_list,depth = 4)

j =tf.constant(np.array([3.,7.,10.]))
j

np.array(j)

